---
title: "Times series clustering"
author: "Mar Garcia-Aloy"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    toc: true
    number_sections: false
    toc_float: true
---

```{r startpoint, include = FALSE}
startpoint <- Sys.time()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

In this document we do time-series clustering of discriminant compounds from `maturation study` using the functions available in the package `dtwclust`.  
First of all, we load the necessary libraries, import the study data, generate the GAM models, select the discriminant compounds and compute a new data matrix with the predicted values obtained by the GAM models.  


# Preliminaries

```{r preliminaries}
# Load the packages
library(readxl)
library(xcms)
library(mgcv)
library(dtwclust)
library(TSdist)

# Data import
brix <- readxl::read_excel("data/Grape_Brix_Datafile.xlsx")
brix$data <- as.character(brix$data)
brix <- rbind(
  brix, 
  c(2019, "diradamento", "corno - az. Oliva", "2019-09-17", "C", 0, 
    mean(brix$Brix[brix$data == "2019-09-17"])),
  c(2019, "diradamento", "corno - az. Oliva", "2019-09-24", "C", 0, 
    mean(brix$Brix[brix$data == "2019-09-24"])))
brix <- brix[order(brix$data, brix$Replicate), ]
xtime <- as.integer(as.Date(brix$data))

data <- read_xlsx("data/data_maturation.xlsx", sheet = "loq_data")
colnames(data)[1] <- "ID"
fl <- "C:/Users/garciaalom/Google Drive/projectes/lipidomics_shared/new_rt.xlsx"
#fl <- "data/new_rt.xlsx"
cmps <- rbind(read_xlsx(fl, sheet = "IS")[, 1:2],
              read_xlsx(fl, sheet = "FORMULE")[, 1:2])
cmps$ID <- gsub("_Na", "", cmps$ID)
cmps <- cmps[cmps$ID %in% data$ID, ]
cmps <- cmps[match(data$ID, cmps$ID), ]
cmps$ID <- data$ID <- gsub("[^0-9A-Za-z///' ]", "_", cmps$ID)
cmps$ID <- data$ID <- gsub("/", "_", cmps$ID)
cmps$ID <- data$ID <- gsub(" ", "_", cmps$ID)
cmps$ID <- data$ID <- gsub("__", "_", cmps$ID)
idx <- grep("_$", cmps$ID)
cmps$ID[idx] <- data$ID[idx] <- substr(cmps$ID[idx], 1, 
                                       nchar(cmps$ID[idx])-1)
data <- data[,-1]
data <- sapply(data, as.numeric)
rownames(data) <- cmps$ID

class <- colnames(data)
class <- gsub("_Rep.*", "", class)
class <- gsub("_MIX.*", "", class)
class[grep("QC", class)] <- "QC"
data <- data[, class != "QC"]
class <- class[class != "QC"]
na_n <- aggregate(t(data), by=list(class), function(x){sum(!is.na(x))})
na_n <- apply(na_n[,-1], 2, max)
cmps <- cmps[cmps$ID %in% rownames(data)[na_n > 2], ]
data <- data[na_n > 2, ]
rownames(data) <- cmps$ID

# GAM models
data <- data[!rownames(data) %in% cmps$ID[cmps$class == "IS"], 
             !grepl("QC", colnames(data))]
set.seed(123)
dt <- t(imputeRowMinRand(as.matrix(data), method = "from_to",
                         min_fraction = 1/100,
                         min_fraction_from = 1/1000))

stat.gam <- function(x){
  as.numeric(unlist(summary(
    gam(log10(x) ~ s(xtime), method = "REML", gamma = 1.4)
  ))["s.table4"])
}
pval <- apply(FUN = stat.gam, MARGIN = 2, X = dt)
padj <- p.adjust(pval, "BH")

stat.dev <- function(x){
  summary(gam(log10(x) ~ s(xtime), method = "REML", gamma = 1.4))$dev.expl 
}
dev <- apply(FUN = stat.dev, MARGIN = 2, X = dt)

dt <- dt[, padj < 0.05 & dev > 0.7]
```


# Clustering

There are the following elements to consider when doing time-series clustering:  

- Distance measure    
- Clustering algorithm  
- Prototype definition (i.e., centroid)  
- Output evaluation  

There are different algorithms and methods for each of these elements. 
We have chosen `dtw_basic` (*Dynamic Time Warp*) to compute the distance matrix, 
`partitional` as the clustering algorithm and 
`pam` (*Partition Around Medoids*) as the method for calculating centroids.  
As evaluation parameter we will use the `within cluster sum of squares` (WCSS) 
and `average between clusters sum of squares` (aBCSS). 
Ideally, the WCSS should be as small as possible and aBCSS as big as possible.


## Predicted values

## 50 time points

```{r predicted-models-50}
ytimes <- seq(min(xtime), max(xtime))
dt_pred <- matrix(NA, nrow = length(ytimes), ncol = ncol(dt))
colnames(dt_pred) <- colnames(dt)

for(i in seq(ncol(dt_pred))){
  dt_pred[,i] <- predict.gam(
    gam(log10(dt[,i]) ~ s(xtime), method = "REML", gamma = 1.4), 
    data.frame(xtime = ytimes))  
}
dt_pred_sc <- scale(dt_pred)
dt_pred_sc_t <- t(dt_pred_sc)
pc_k_pred <- tsclust(dt_pred_sc_t, type = "partitional", 
                     k = 2L:(nrow(dt_pred_sc_t)-1), preproc = NULL,
                     distance = "dtw_basic", centroid = "pam", seed = 202104)

pc_within <- c()
pc_between <- c()
for(i in seq(length(pc_k_pred))){
  # vector with the distance between each series in the data and its 
  # corresponding centroid
  k.cldist <- pc_k_pred[[i]]@cldist
  
  # Within cluster sum of squares: sum of the squared deviations from each 
  # observation and the cluster centroid
  pc_within <- c(pc_within, sum(k.cldist^2))
  
  # list with the centroid time series
  k_centr <- pc_k_pred[[i]]@centroids
  k_centr <- do.call(rbind.data.frame, k_centr)
  # Average Between Clusters Sum of Squares: squared average distance between all centroids
  pc_between <- c(pc_between, mean(c(TSDatabaseDistances(k_centr, distance = "dtw"))^2))
}
plot(2:(length(pc_k_pred)+1), pc_within, type = "l",
     xlab = "n clusters", ylab = "", ylim = c(0, max(pc_within, pc_between)))
points(2:(length(pc_k_pred)+1), pc_between, type = "l", col = "red")
legend("topright", col = seq(2), pch = 16,
       legend = c("Within cluster sum of squares", 
                  "Between cluster sum of squares (average)"))

plot(2:(length(pc_k_pred)+1), pc_within, type = "l",
     xlab = "n clusters", ylab = "", 
     ylim = c(0, max(pc_within, pc_between)), xlim = c(2,15))
points(2:(length(pc_k_pred)+1), pc_between, type = "l", col = "red")

for(i in seq(10)){
  plot(pc_k_pred[[i]])
}
```

## 13 time points

```{r predicted-models-13}
dt_pred <- matrix(NA, nrow = length(unique(xtime)), ncol = ncol(dt))
colnames(dt_pred) <- colnames(dt)

for(i in seq(ncol(dt_pred))){
  dt_pred[,i] <- predict.gam(
    gam(log10(dt[,i]) ~ s(xtime), method = "REML", gamma = 1.4), 
    data.frame(xtime = unique(xtime)))  
}
dt_pred_sc <- scale(dt_pred)
dt_pred_sc_t <- t(dt_pred_sc)
pc_k_pred <- tsclust(dt_pred_sc_t, type = "partitional", 
                     k = 2L:(nrow(dt_pred_sc_t)-1), preproc = NULL,
                     distance = "dtw_basic", centroid = "pam", seed = 202104)

pc_within <- c()
pc_between <- c()
for(i in seq(length(pc_k_pred))){
  # vector with the distance between each series in the data and its 
  # corresponding centroid
  k.cldist <- pc_k_pred[[i]]@cldist
  
  # Within cluster sum of squares: sum of the squared deviations from each 
  # observation and the cluster centroid
  pc_within <- c(pc_within, sum(k.cldist^2))
  
  # list with the centroid time series
  k_centr <- pc_k_pred[[i]]@centroids
  k_centr <- do.call(rbind.data.frame, k_centr)
  # Average Between Clusters Sum of Squares: squared average distance between all centroids
  pc_between <- c(pc_between, mean(c(TSDatabaseDistances(k_centr, distance = "dtw"))^2))
}
plot(2:(length(pc_k_pred)+1), pc_within, type = "l",
     xlab = "n clusters", ylab = "", ylim = c(0, max(pc_within, pc_between)))
points(2:(length(pc_k_pred)+1), pc_between, type = "l", col = "red")
legend("topright", col = seq(2), pch = 16,
       legend = c("Within cluster sum of squares", 
                  "Between cluster sum of squares (average)"))

plot(2:(length(pc_k_pred)+1), pc_within, type = "l",
     xlab = "n clusters", ylab = "", 
     ylim = c(0, max(pc_within, pc_between)), xlim = c(2,20))
points(2:(length(pc_k_pred)+1), pc_between, type = "l", col = "red")

for(i in seq(10)){
  plot(pc_k_pred[[i]])
}
```

## Raw values

```{r raw-models}
# Calculate mean values of each compound in each time-point
dt_mean <- matrix(NA, nrow = length(unique(xtime)), ncol = ncol(dt))
colnames(dt_mean) <- colnames(dt)
rownames(dt_mean) <- unique(xtime)
for(i in seq(ncol(dt_mean))){
  dt_mean[,i] <- aggregate(dt[,i], list(xtime), mean)[,"x"]
}

dt_log_sc <- scale(log10(dt_mean))
dt_log_sc_t <- t(dt_log_sc)

pc_k_raw <- tsclust(dt_log_sc_t, type = "partitional", 
                    k = 2L:(nrow(dt_pred_sc_t)-1), preproc = NULL,
                    distance = "dtw_basic", centroid = "pam", seed = 202104)

pc_within <- c()
pc_between <- c()
for(i in seq(length(pc_k_pred))){
  # vector with the distance between each series in the data and its 
  # corresponding centroid
  k.cldist <- pc_k_pred[[i]]@cldist
  
  # Within cluster sum of squares: sum of the squared deviations from each 
  # observation and the cluster centroid
  pc_within <- c(pc_within, sum(k.cldist^2))
  
  # list with the centroid time series
  k_centr <- pc_k_pred[[i]]@centroids
  k_centr <- do.call(rbind.data.frame, k_centr)
  # Average Between Clusters Sum of Squares: squared average distance between all centroids
  pc_between <- c(pc_between, mean(c(TSDatabaseDistances(k_centr, distance = "dtw"))^2))
}

plot(2:(length(pc_k_pred)+1), pc_within, type = "l",
     xlab = "n clusters", ylab = "", ylim = c(0, max(pc_within, pc_between)))
points(2:(length(pc_k_pred)+1), pc_between, type = "l", col = "red")
legend("topright", col = seq(2), pch = 16,
       legend = c("Within cluster sum of squares", 
                  "Between cluster sum of squares (average)"))

plot(2:(length(pc_k_pred)+1), pc_within, type = "l",
     xlab = "n clusters", ylab = "", 
     ylim = c(0, max(pc_within, pc_between)), xlim = c(2,20))
points(2:(length(pc_k_pred)+1), pc_between, type = "l", col = "red")

for(i in seq(10)){
  plot(pc_k_raw[[i]])
}
```

## Confusion matrix predicted (x13) - raw

Below we print the outputs of the clusterings with the predicted values *versus* 
the raw values in order to see how similar they are:

```{r confusion-matrix}
for(i in seq(10)){
  print(table(pc_k_pred[[i]]@cluster, 
              pc_k_raw[[i]]@cluster))
}
```

# Gam 2x2

Here, what we do is to compare if the trend over time of metabolites is equal or 
not by doing pairwise comparisons within a fitted GAM. 
For that, what we do each time is to fit a GAM with the data of 2 metabolites and 
check if p-value that corresponds to the interaction factor time*metabolite (i.e., `s(xtime):as.numeric(factor(met))`) is statistically significant or not:

```{r gam-2x2-exemple}
met_pair <- data.frame(
  combn(c(colnames(dt)[1:round(ncol(dt)/2)], 
          colnames(dt)[(round(ncol(dt)/2)+1):ncol(dt)]), 2))
met_pair[3, ] <- NA
dt_log_sc <- scale(log(dt))
i <- 1
tmp <- data.frame(rbind(cbind(dt_log_sc[,met_pair[1,i]], xtime, rep(met_pair[1,i], 63)),
                        cbind(dt_log_sc[,met_pair[2,i]], xtime, rep(met_pair[2,i], 63))))
colnames(tmp) <- c("value", "xtime", "met")
tmp$value <- as.numeric(tmp$value)
tmp$xtime <- as.numeric(tmp$xtime)
summary(
  gam(value ~ s(xtime) + s(xtime, by = as.numeric(factor(met))), 
      method = "REML", gamma = 1.4, data = tmp)
)
```

Later, with this information we create a matrix of 0 and 1 values indicating if 
this p-value is <0.05 (1) or not (0) in order to visualize the output as a network.

```{r gam-2x2-execute}
for(i in seq(ncol(met_pair))){
  tmp <- data.frame(rbind(cbind(dt_log_sc[,met_pair[1,i]], xtime, rep(met_pair[1,i], 63)),
                          cbind(dt_log_sc[,met_pair[2,i]], xtime, rep(met_pair[2,i], 63))))
  colnames(tmp) <- c("value", "xtime", "met")
  tmp$value <- as.numeric(tmp$value)
  tmp$xtime <- as.numeric(tmp$xtime)
  met_pair[3, i] <- (summary(
    gam(value ~ s(xtime) + s(xtime, by = as.numeric(factor(met))), 
        method = "REML", gamma = 1.4, data = tmp)))$s.table[
          "s(xtime):as.numeric(factor(met))", "p-value"]
}

met_pair_t <- data.frame(t(met_pair))
colnames(met_pair_t) <- c("met1", "met2", "pval")
met_pair_t$pval <- as.numeric(met_pair_t$pval)
nrow(met_pair_t) # n. pair-wise metabolite comparisons
sum(met_pair_t$pval < 0.05) # n. of significant pair-wise metabolite comparisons
(sum(met_pair_t$pval < 0.05)/nrow(met_pair_t))*100 # % of significant pair-wise metabolite comparisons
met_pair_t$pval <- p.adjust(met_pair_t$pval, "bonferroni")
sum(met_pair_t$pval < 0.05) # n. of significant pair-wise metabolite comparisons (adjusted p-val)
(sum(met_pair_t$pval < 0.05)/nrow(met_pair_t))*100 # % of significant pair-wise metabolite comparisons (adjusted p-val)

met_pair_t$link <- ifelse(met_pair_t$pval < 0.05, 1, 0)

links <- met_pair_t[met_pair_t$link == 1, c(1, 2, 4)]
nodes <- cmps[cmps$ID %in% c(links$met1, links$met2), c(2, 1)]
library(igraph)
net <- graph_from_data_frame(d=links, vertices=nodes, directed=T) 
net <- simplify(net, remove.multiple = F, remove.loops = T) 
library(RColorBrewer)
colrs <- colorRampPalette(brewer.pal(12, "Paired"))(length(unique(nodes$class)))
names(colrs) <- unique(nodes$class)
V(net)$color <- colrs[V(net)$class] # colors based on compound classes

plot(net, edge.arrow.size = .1, vertex.label = NA, vertex.size = 5)
```


```{r network, fig.width = 15, fig.height = 25}
layouts <- grep("^layout_", ls("package:igraph"), value=TRUE)[-1] 
# Remove layouts that do not apply to our graph.
layouts <- layouts[!grepl("bipartite|sugiyama", layouts)]
layouts <- layouts[!grepl("dh", layouts)] #slow

par(mfrow = c(5, 3), mar = c(1,1,1,1))
for (layout in layouts) {
  l <- do.call(layout, list(net)) 
  plot(net, edge.arrow.mode = 0, vertex.label = NA, vertex.size = 5, 
       layout = l, main = layout) 
}
```


# Session information

```{r session}
Sys.time()-startpoint
devtools::session_info()
```
