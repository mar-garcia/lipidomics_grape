---
title: "Data analysis: maturation"
author: "Mar Garcia-Aloy"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    toc: true
    number_sections: false
    toc_float: true
---

```{r startpoint, include = FALSE}
startpoint <- Sys.time()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

This document belongs to the project of application of the new targeted lipidomics method to grape samples collected at different maturation stages.  

# Libraries

```{r libraries}
library(readxl)
library(xcms)
library(plotly)
library(pheatmap)
library(RColorBrewer)
library(knitr)
library(car)
library(mgcv)
library(beeswarm)
library(ggplot2)
library(gridExtra)
library(dtwclust)
library(rstatix)
library(igraph)
```


# Read data

```{r import-data}
# Import compound quantification data:
data <- read_xlsx("data/data_maturation.xlsx", sheet = "loq_data")
colnames(data)[1] <- "ID"

# Create a vector specifying the sample classes:
class <- colnames(data)[-1]
class <- gsub("_Rep.*", "", class)
class <- gsub("_MIX.*", "", class)
class[grep("QC", class)] <- "QC"

# Load compound annotations:
fl <- "C:/Users/garciaalom/Google Drive/projectes/lipidomics_shared/new_rt.xlsx"
#fl <- "data/new_rt.xlsx"
cmps <- rbind(read_xlsx(fl, sheet = "IS")[, 1:2],
              read_xlsx(fl, sheet = "FORMULE")[, 1:2])
cmps$ID <- gsub("_Na", "", cmps$ID)
cmps <- cmps[cmps$ID %in% data$ID, ]
cmps <- cmps[match(data$ID, cmps$ID), ]

# Replace R problematic symbols in compound names:
all(cmps$ID == data$ID) # TRUE
cmps$ID <- data$ID <- gsub("[^0-9A-Za-z///' ]", "_", cmps$ID)
cmps$ID <- data$ID <- gsub("/", "_", cmps$ID)
cmps$ID <- data$ID <- gsub(" ", "_", cmps$ID)
cmps$ID <- data$ID <- gsub("__", "_", cmps$ID)
idx <- grep("_$", cmps$ID)
cmps$ID[idx] <- data$ID[idx] <- substr(cmps$ID[idx], 1, nchar(cmps$ID[idx])-1)
data <- data[,-1]
data <- sapply(data, as.numeric)
rownames(data) <- cmps$ID
```

Below we import and plot the data regarding the brix degree of collected samples according to the sampling date.  

```{r brix}
brix <- readxl::read_excel("data/Grape_Brix_Datafile.xlsx")
plot(as.Date(brix$data), brix$Brix, 
     col = brix$Replicate + 1, pch = 16, xlab = "Date", ylab = "Brix")
legend("bottomright", legend = paste("Rep ", seq(5)), col = 2:6, pch = 16)
```

The dataset contains information about the quantification of n=`r nrow(data)` compounds in n=`r ncol(data)` samples of the following classes: `r paste0(aggregate(class, list(class), function(x){sum(class == x)})[,1], " (n=", aggregate(class, list(class), function(x){sum(class == x)})[,2], ")", collapse = "; ")`. 

Missing values (n=`r sum(is.na(data))`) in the dataset will be replaced by a random value between the range obtained by dividing by 1000 and 100 of the smallest measured concentration for the corresponding compound.    
Principal component analysis (PCA) and heatmaps will be performed on log-transformed and Pareto-scaled abundances, whereas generalized additive models (GAM) on log-transformed data.  

## Massimo valore trovato per classe 

```{r}
tmp_dt <- data
tmp_dt[is.na(tmp_dt)] <- 0
rownames(tmp_dt) <- rownames(data)
cmps.class <- unique(cmps$class)
for(i in 2:(length(cmps.class))){
  tmp <- apply(tmp_dt[cmps$ID[cmps$class == cmps.class[i]],], 1, max)
  print(paste(cmps.class[i], 
              cmps$ID[cmps$class == cmps.class[i]][which.max(tmp)], 
              round(max(tmp), 1), 
              sep = " - "))
}
```

# Exploratory data analysis

As mentioned, we start with an exploratory analysis of the data, first using all compounds and all samples and then only with samples of interest and excluding some potential problematic compounds.


## All samples

### PCA

```{r pca-all}
scaling.pareto <- BioMark::scalefun(sc.p="pareto")

set.seed(123)
dt <- t(imputeRowMinRand(as.matrix(data), method = "from_to",
                         min_fraction = 1/100,
                         min_fraction_from = 1/1000))
colnames(dt) <- rownames(data)
dt <- log10(dt)
dt <- data.frame(scaling.pareto(dt))
idx <- (colSums(is.na(dt)) == 0)
dt <- dt[, idx]
pca <- prcomp(dt, center = FALSE, scale. = FALSE)
tmp <- data.frame(pca$x)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = class)
```

`QC` samples are clustered together close to the origin of the scores plot. They show a lower dispersion between them compared to that observed among the study samples and also among the samples from the same study group (i.e., time-point), indicating a good analytical reproducibility (i.e., the variability due to the analytical platform is smaller than the biological/technical variability between the samples, eiher the ones collected at the same moment).  

Visual inspection of the PCA score shows a certain degree of separation between the first and second half of samples along the first two components (accounting for `r round(summary(pca)$importance[2,1]*100, 1)`% and `r round(summary(pca)$importance[2,2]*100, 1)`% of the total variance explained, respectively).  
To visualize this more clearly, the samples below are coloured according to whether they belong to the first or the second half of sampling:


```{r pca-all-2}
class2 <- class
class2[class2 %in% c("Pt_01", "Pt_02", "Pt_03", "Pt_04", "Pt_05", 
                     "Pt_06")] <- "Pt_01_06"
class2[class2 %in% c("Pt_07", "Pt_08", "Pt_09", "Pt_10", "Pt_11", 
                     "Pt_12", "Pt_13")] <- "Pt_07_13"
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = class2)


tmp <- data.frame(pca$rotation)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = cmps$class[idx])
```

The distribution of the compounds along the first 2 components in the loading plot does not match the same pattern observed in the samples: while in the case of samples a separation according to the sampling time is observed along a diagonal that goes from the upper-right corner to the lower-left corner, the compounds seem to be distributed along a diagonal that goes from the upper-left corner to the lower-right corner.   
However, it can be clearly observed how the `TAGs` are located outside this diagonal in the lower-left quadrant of the graph, although *a priori* it is not easy to associate them to a certain group of samples.


### Heatmap

```{r heatmap-all, fig.height=10, fig.width=14}
dt_pt <- data.frame(point = class)
rownames(dt_pt) <- rownames(dt)

dt_class <- data.frame(class = cmps$class[idx])
rownames(dt_class) <- colnames(dt)

n.pt <- length(unique(dt_pt$point))
n.class <- length(unique(dt_class$class))

ann_color <- list(
  "time-point" = colorRampPalette(brewer.pal(9, "Set1"))(n.pt),
  "class" = colorRampPalette(brewer.pal(12, "Paired"))(n.class)
)
names(ann_color[[1]]) <- unique(dt_pt$point)
names(ann_color[[2]]) <- unique(dt_class$class)

pheatmap(dt, show_colnames = F, show_rownames = F, 
         annotation_row = dt_pt, annotation_col = dt_class,
         annotation_colors = ann_color)


dt_pt2 <- data.frame(point = class2)
rownames(dt_pt2) <- rownames(dt)

ann_color <- list(
  "time-point" = brewer.pal(3, "Set2"),
  "class" = colorRampPalette(brewer.pal(12, "Paired"))(n.class)
)
names(ann_color[[1]]) <- unique(dt_pt2$point)
names(ann_color[[2]]) <- unique(dt_class$class)

pheatmap(dt, show_colnames = F, show_rownames = F, 
         annotation_row = dt_pt2, annotation_col = dt_class,
         annotation_colors = ann_color)
```


## Quality control samples

We check (and, if any, list) if there are compounds not detected in all QC samples:


```{r qc}
idx <- which(rowSums(is.na(data[, class == "QC"])) > 0)
tmp <- data[idx, class == "QC"]
rownames(tmp) <- rownames(data)[idx]
kable(tmp)
```

Next we calculate the CV across QC samples to check the quality of acquired data and their distribution is plotted below:

```{r qc-cv}
CV <- function(x){(sd(x)/mean(x))*100}
CV_QC <- apply(data[, class == "QC"], 1, CV)
plot(density(CV_QC, na.rm = TRUE), xlab = "CV (%)", main = "")
```

The CV is arround or below 10% for most of the compounds, but some have a higher CV.  
The following table shows the the amount of compounds with specific CV intervals:  

```{r qc-cv-table}
kable(table(cut(CV_QC, c(0, 10, 20, 30, 50, 80, max(CV_QC, na.rm = T)))))
```

Below it is plotted the distribution within QC samples of the 4 compounds with the highest CV in QCs:

```{r qc-cv-plot, fig.height = 7}
par(mfrow = c(2, 2))
idx <- order(CV_QC, decreasing = T)[1:4]
for(i in seq(4)){
  plot(data[idx[i], class == "QC"], xlab = "", ylab = "", pch = 16, 
       main = paste0(rownames(data)[idx][i], " (CV=", round(CV_QC[idx[i]]), "%)"))
}
```

<span style="color:red">**We still have to decide if to exclude some compounds based what it has been observed within QC samples.**</span>  


## Study samples

Below, we will repeat the unsupervised exploratory data anlyses, but this time excluding the `QC` samples, and `IS` compounds and potentially problematic analytes.

```{r filter-data}
class_st <- class[class != "QC"]

data_st <- data[, class != "QC"]
rownames(data_st) <- rownames(data)

data_st <- data_st[cmps$class != "IS", ]
cmps <- cmps[cmps$class != "IS",]
rownames(data_st) <- cmps$ID

na_n <- apply(data_st, 1, function(x) length(which(is.na(x))))
table(na_n)

#idx <- which(na_n > 30)
#kable(t(data_st[idx,]))

na_n <- aggregate(t(data_st), by=list(class_st), function(x){sum(!is.na(x))})
na_n <- apply(na_n[,-1], 2, max)
head(na_n[order(na_n)], 20)
```

There are n=`r sum(na_n == 0)` compounds (`r names(which(na_n == 0))`) that have `NA` values for all study samples. These compounds are excluded from the dataset.  
Additionally, there are n=`r sum(na_n == 1 | na_n == 2)` compounds (`r names(which(na_n == 1 | na_n == 2))`) that, although they were detected in >1 sample, they have only been detected at maximum in 1 or 2 samples sample within a same class. These compounds are excluded from the dataset.      
<span style="color:red">**We still have to decide if to exclude some or all of these compounds.**</span>  

```{r}
cmps <- cmps[cmps$ID %in% rownames(data_st)[na_n > 2], ]
data_st <- data_st[na_n > 2, ]
rownames(data_st) <- cmps$ID
```


### PCA

```{r pca-st}
set.seed(123)
dt <- t(imputeRowMinRand(as.matrix(data_st), method = "from_to",
                         min_fraction = 1/100,
                         min_fraction_from = 1/1000))
dt <- log10(dt)
dt <- data.frame(scaling.pareto(dt))
pca <- prcomp(dt, center = FALSE, scale. = FALSE)
tmp <- data.frame(pca$x)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = class_st)

all(cmps$ID == rownames(data_st)) # TRUE
tmp <- data.frame(pca$rotation)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = cmps$class)
```


### Heatmap

```{r heatmap-st}
dt_pt2 <- data.frame(point = class2[class != "QC"])
rownames(dt_pt2) <- rownames(dt)

ann_color <- list(
  "time-point" = brewer.pal(3, "Set2"),
  "class" = colorRampPalette(brewer.pal(12, "Paired"))(n.class)
)
names(ann_color[[1]]) <- unique(dt_pt2$point)
names(ann_color[[2]]) <- unique(dt_class$class)

pheatmap(dt, show_colnames = F, show_rownames = F, 
         annotation_row = dt_pt2, annotation_col = dt_class,
         annotation_colors = ann_color)
```


# Differential abundance analysis

Generalised Additive Models (GAMs) are performed to identify those compounds that show specific trends over time. GAMs have been selected since they also catch those trends that do not fit a simple linear model.  
GAMs are regression models which allow for the inclusion of a non-parametric smoothing and will fit a regression spline to the data, allowing for nonlinear relationships.   

Sources:   

- http://environmentalcomputing.net/intro-to-gams/  
- https://www.nature.com/articles/hortres201738  

```{r impute-na}
set.seed(123)
dt <- t(imputeRowMinRand(as.matrix(data_st), method = "from_to",
                         min_fraction = 1/100,
                         min_fraction_from = 1/1000))
```


## Assumtions

### Homogeneity of variance

Below we apply the function `leveneTest()` from `car` package to the log-transformed data to check the homogeneity of variances across the time-defined groups using the **Levene's test**.  

```{r variance}
stat.levene <- function(x){
  unlist(leveneTest(log10(x) ~ factor(class_st)))["Pr(>F)1"]
}
lev <- apply(FUN = stat.levene, MARGIN = 2, X = dt)
hist(lev, breaks = 32)
summary(lev)
```

For n=`r sum(lev < 0.05)` out of `r ncol(dt)` (`r round((sum(lev < 0.05) / ncol(dt))*100, 1)`%) compounds, the homoscedasticity assumption is violated. 


### Normality

The **Shapiro-Wilk test** on the GAM residuals is used to check if the residuals satisfy the homoscedasticity assumption. 

```{r normality}
brix$data <- as.character(brix$data)
brix <- rbind(brix, 
              c(2019, "diradamento", "corno - az. Oliva", "2019-09-17", "C", 0, 
                mean(brix$Brix[brix$data == "2019-09-17"])),
              c(2019, "diradamento", "corno - az. Oliva", "2019-09-24", "C", 0, 
                mean(brix$Brix[brix$data == "2019-09-24"])))
brix <- brix[order(brix$data, brix$Replicate), ]
xtime <- as.integer(as.Date(brix$data))

stat.shap <- function(x){
  as.numeric(unlist(shapiro.test(residuals.gam(
    gam(log10(x) ~ s(xtime), method = "REML", gamma = 1.4)
  )))["p.value"])
}
shap <- apply(FUN = stat.shap, MARGIN = 2, X = dt)
hist(shap, breaks = 32)
summary(shap)
```

In this case, it can be seen that for a total of `r sum(shap < 0.05)` out of `r ncol(dt)` (`r round((sum(shap < 0.05) / ncol(dt))*100, 1)`%) compounds, the normality assumption is violated.   


## Compute the test 

GAMs are fitted by using the `gam` function of the `mgcv` package on log-transformed data.  
GAMs are fitted by using the restricted maximum likelihood (REML) algorithm because REML estimates are more nearly unbiased in presence of small data sets.  
<span style="color:red">**To do**: ask Pietro why we are modeling with the parameter `gamma = 1.4`.</span>    
Raw p-values are adjusted for multiple hypothesis testing with the method from Benjamini and Hochberg.  
Analytes will be considered significant if they have an adjusted p-value smaller than 0.05 (representing a 5% false discovery rate) and if the proportion of the null deviance explained by the corresponding model is higher than 0.7 (in order to focus on those compounds for which, in addition to show statistical significance,  the model is also able to correctly predict the observed values).

```{r gam}
stat.gam <- function(x){
  as.numeric(unlist(summary(
    gam(log10(x) ~ s(xtime), method = "REML", gamma = 1.4)
  ))["s.table4"])
}
pval <- apply(FUN = stat.gam, MARGIN = 2, X = dt)
padj <- p.adjust(pval, "BH")
par(mfrow = c(1, 2))
hist(pval, breaks = 32)
hist(padj, breaks = 32)
```

There is a clear enrichment of small p-values.  

```{r gam-cor-pred}
stat.dev <- function(x){
  summary(gam(log10(x) ~ s(xtime), method = "REML", gamma = 1.4))$dev.expl 
}
dev <- apply(FUN = stat.dev, MARGIN = 2, X = dt)
hist(dev)

par(mfrow = c(1, 2))
plot(dev, padj)
abline(h = 0.05, v = 0.7, lty = 2, col = "grey")

padj.log <- -log10(padj)
padj.log[padj.log == "Inf"] <- -log10(min(padj[padj > 0])/10)
plot(dev, padj.log)
abline(h = -log10(0.05), v = 0.7, lty = 2, col = "grey")
```


<span style="color:red">**Should we reduce the threshold on `dev` parameter to 0.6 or even 0.51?**</span>  


## Discriminant compounds

A total of n=`r sum(padj < 0.05)` compounds (`r round((sum(padj < 0.05)/nrow(data_st))*100, 1)`%) are found to present significant time-related trends, whereas n=`r sum(padj < 0.05 & dev > 0.7)` of them (`r round((sum(padj < 0.05 & dev > 0.7)/sum(padj < 0.05))*100, 1)`%) also adjust to a model that fits the data.   

Below there is plotted again the loadings plot of the PCA and the heatmap highlighting the discriminant compounds.

```{r discriminants}
tmp <- data.frame(pca$x)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = class2[class != "QC"])

tmp_col <- rep("NS", ncol(dt))
tmp_col[padj < 0.05] <- "padj < 0.05"
tmp_col[padj < 0.05 & dev > 0.7] <- "padj < 0.05 & dev.expl > 0.7"

tmp <- data.frame(pca$rotation)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = tmp_col, colors = c("#377EB8", "#4DAF4A", "#E41A1C"))

dt_sig <- data.frame(significe = tmp_col)
dt_sig$significe <- as.factor(dt_sig$significe)
rownames(dt_sig) <- colnames(dt)
ann_color <- list(
  "time-point" = brewer.pal(5, "Set1")[4:5],
  "significe" =  brewer.pal(3, "Set1")
)
names(ann_color[[1]]) <- unique(dt_pt2$point)
names(ann_color[[2]]) <- levels(dt_sig$significe)
pheatmap(data.frame(scaling.pareto(log10(dt))), 
         annotation_row = dt_pt2, annotation_col = dt_sig,
         annotation_colors = ann_color, show_colnames = F, show_rownames = F)
```


## Clusters of time-trends 

Discriminant compounds are grouped according to their time-trends observed in GAM models. 
For that, we first create a new matrix of predicted values over 50 time-points, starting and finishing from the first and last sample collection date, respectively.  
Then, we do time-series clustering of discriminant compounds using the functions available in the package `dtwclust`. As a distance measure we use the algorithm `dtw_basic` (i.e., *dynamic time warping*). In addition to use logarithmic data to compute the distance matrix, for this estimation the values are also scaled. Clustering based on slope/shape/trend similarity over time is done using the algorithm `partitional` and cluster centroids are calculated with the `pam` (i.e., (*partition around medoids*) method.

```{r pred-cor}
idx <- which(padj < 0.05 & dev > 0.7)

ytimes <- seq(min(xtime), max(xtime))
dt_pred <- matrix(NA, nrow = length(ytimes), ncol = ncol(dt))
colnames(dt_pred) <- colnames(dt)
dt_pred <- dt_pred[,idx]

for(i in seq(ncol(dt_pred))){
  dt_pred[,i] <- predict.gam(
    gam(log10(dt[,idx[i]]) ~ s(xtime), method = "REML", gamma = 1.4), 
    data.frame(xtime = ytimes))  
}


dt_pred_s <- scale(dt_pred)
dt_pred_s_t <- t(dt_pred_s)
pc_k_pred <- tsclust(dt_pred_s_t, type = "partitional", k = 2, preproc = NULL,
                     distance = "dtw_basic", centroid = "pam", seed = 202104)
pc_k_pred@clusinfo
plot(pc_k_pred)

cl_k <- data.frame(cluster = paste0("c", pc_k_pred@cluster))
rownames(cl_k) <- rownames(dt_pred_s_t)

pm <- pheatmap(pc_k_pred@distmat, show_colnames = F, show_rownames = F,
               color = colorRampPalette(brewer.pal(n = 7, name = "RdYlBu"))(100),
               #cutree_rows = 5, cutree_cols = 5, 
               annotation_row = cl_k, annotation_col = cl_k, legend = FALSE,
               main = "Clustering of distance measurements on predicted data")

#pheatmap(as.matrix(pc_k_pred@distmat)[order(cl_k$cluster, pm$tree_row$order),
#                                 order(cl_k$cluster, pm$tree_row$order)], 
#         show_colnames = F, show_rownames = F,
#         color = colorRampPalette(brewer.pal(n = 7, name = "RdYlBu"))(100),
#         annotation_row = cl_k, annotation_col = cl_k, legend = FALSE,
#         main = "Clustering of distance measurements on predicted data",
#         cluster_rows = F, cluster_cols = F)
```

<span style="color:red">**We still have to discuss if we are happy with these clusters or if we want to change something (i.e. algorithm of distance matrix generation, clustering or number of clusters).**</span>  
In order to visualize these different *prototypes*, we overplot the log-scaled-data of each compound belonging to each cluster (each cluster is plotted separately). Points refer to measured data, whereas lines the generated GAM models.

```{r clusters, fig.width = 14}
dt <- dt[,padj < 0.05 & dev > 0.7]
data_st_log <- log10(dt)
data_st_log_s <- scale(data_st_log)
par(mfrow = c(1, 2), mar = c(0.5, 0.5, 2, 0.5))
for(j in seq(2)){
  idx <- which(pc_k_pred@cluster == j)
  if(length(idx) > 9){
    clrs <- colorRampPalette(brewer.pal(9, "Set1"))(length(idx))
  } else{
    clrs <- brewer.pal(length(idx), "Set1")
  }
  i <- 1
  plot(xtime, data_st_log_s[,idx[i]], pch = 16, col = alpha(clrs[i], 0.6), 
       ylim = c(min(c(dt_pred_s_t[idx,], data_st_log_s[,idx])), 
                max(c(dt_pred_s_t[idx,], data_st_log_s[,idx]))),
       main = paste("cluster", j))
  points(ytimes, dt_pred_s_t[idx[i],], pch = 16, col = clrs[i], type = "l", 
         lwd = 2)
  for(i in 2:length(idx)){
    points(xtime, data_st_log_s[,idx[i]], pch = 16, col = alpha(clrs[i], 0.6))
    points(ytimes, dt_pred_s_t[idx[i],], col = clrs[i], pch = 16, type = "l", 
           lwd = 2)
  }
  plot(0, 0, axes = FALSE, frame.plot = FALSE, xlab = "", ylab = "")
  legend("topleft", legend = colnames(data_st_log_s)[idx], pch = 16,
         col = clrs, ncol = 4, box.lwd = 0, box.col = "white", 
         cex = 0.8)
}
```

Next, visualize on a network the obtained results (linking only those compounds with a similarity > 0.7):

```{r network}
#links <- 1-as.matrix(dt_pred_dist)
links <- cor(dt_pred_s)
for(i in 1:ncol(links)){
  links[1:i,i] <- NA
}
links <- cor_gather(links)
links <- links[links$cor > 0.7, ]
nodes <- cmps[cmps$ID %in% links$var1 |
                cmps$ID %in% links$var2, c(2, 1)]
all(rownames(cl_k) == nodes$ID) # TRUE
nodes$cluster <- cl_k$cluster
net <- graph_from_data_frame(d = links, vertices = nodes, directed=T)
net <- simplify(net, remove.multiple = F, remove.loops = T) 
colrs <- colorRampPalette(brewer.pal(12, "Paired"))( length(unique(dt_class$class)))
names(colrs) <- unique(dt_class$class)
V(net)$color <- colrs[V(net)$class] # colors based on compound classes
E(net)$width <- E(net)$cor # Set edge width based on distances
E(net)$arrow.mode <- 0
plot(net, edge.arrow.size = .1, vertex.label = NA, vertex.size = 5, 
     layout = layout_with_graphopt(net), main = "Color according to compound class")
colrs <- brewer.pal(6, "Set1")
names(colrs) <- unique(nodes$cluster)
plot(net, edge.arrow.size = .1, vertex.label = NA, vertex.size = 5, 
     layout = layout_with_graphopt(net), vertex.color=colrs[V(net)$cluster], 
     main = "Color according to cluster")
```

## Other plots

Finally, just for visualization purposes, we compute again both the PCA and heatmap, but this time using only statistically significant compounds:

```{r pca-sig}
data_st_log_par <- data.frame(scaling.pareto(data_st_log))
pca_sig <- prcomp(data_st_log_par, center = FALSE, scale. = FALSE)
tmp <- data.frame(pca_sig$x)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp),
        color = class2[class2 != "QC"])

idx <- which(padj < 0.05 & dev > 0.7)
all(cmps$ID[idx] == rownames(cl_k)) # TRUE
cmps$cluster <- "NS"
cmps$cluster[padj < 0.05 & dev < 0.7] <- "high-dev"
cmps$cluster[idx] <- cl_k$cluster

tmp <- data.frame(pca_sig$rotation)
plot_ly(x = tmp$PC1, y = tmp$PC2,
        text = rownames(tmp), 
        color = cmps$cluster[idx]
)


dt_cl <- data.frame(cluster = cl_k$cluster)
rownames(dt_cl) <- cmps$ID[idx]

ann_color <- list(
  "time-point" = brewer.pal(3, "Set2"),
  "behaviour" = brewer.pal(5, "Set2")
)
names(ann_color[[1]]) <- unique(dt_pt2$point)
names(ann_color[[2]]) <- unique(dt_cl$pm_cl)

pheatmap(data_st_log_par, annotation_row = dt_pt2, annotation_col = dt_cl,
         annotation_colors = ann_color, show_colnames = F, show_rownames = F)
```


```{r plots, eval = FALSE}
cmpsx <- cmps
cmpsx <- cmpsx[order(cmpsx$cluster), ]

set.seed(123)
dt <- t(imputeRowMinRand(as.matrix(data_st), method = "from_to",
                         min_fraction = 1/100,
                         min_fraction_from = 1/1000))

p <- list()
for(i in seq(nrow(cmpsx))){
  x <- as.integer(as.Date(brix$data))
  y <- dt[,cmpsx$ID[i]]
  z <- is.na(data[cmpsx$ID[i], class != "QC"])
  Sample_data <- data.frame(y,x, z)
  Sample_data$class <- class[class != "QC"]
  p[[i]] <- ggplot(Sample_data, aes(x, log10(y))) + 
    geom_point(
      aes(pch = z), position = position_jitter(1), 
      color = colorRampPalette(brewer.pal(9, "YlOrRd"))(13)[as.factor(Sample_data$class)]) + 
    geom_smooth(method = "gam", formula = y ~s(x), col = "grey", alpha = 0.1) +
    xlab("") + ylab("") + theme_light() + theme(legend.position = "none") + 
    ggtitle(ttl <- paste0(cmpsx$ID[i], " (", cmpsx$cluster[i], ")"))
}
ggsave(
  filename = "stats_maturation_curves.pdf",
  plot = marrangeGrob(p, nrow = 4, ncol = 3),
  width = 15, height = 12
)
```

# Classes of compounds

```{r}
idx <- rownames(data) %in% cmps$ID
idx.names <- rownames(data)[idx]
data <- data[idx, class!= "QC"]
rownames(data) <- idx.names
```

Proportion of quantified lipids:

```{r}
slices <- c(mean(colSums(data, na.rm = T)), 1e6 - mean(colSums(data, na.rm = T)))
lbls <- c("lipids", "others")
lbls <- paste0(lbls, "\n(", round(slices/1000), ' mg/g)')
pie(slices, lbls)

y <- aggregate(colSums(data, na.rm = T), list(class[class != "QC"]), mean)[,"x"]
sdx <- aggregate(colSums(data, na.rm = T), list(class[class != "QC"]), sd)[,"x"]

plot(y, 
     pch = 16, xlab = "time point", ylab = "total lipids (ug)", col = 2, 
     ylim = c(min(colSums(data, na.rm = T)), max(colSums(data, na.rm = T))))
points(as.numeric(as.factor(class[class!="QC"])), colSums(data, na.rm = T))
segments(seq(13), y - sdx, 
         seq(13), y + sdx, col = 2)
epsilon <- 0.02
segments(seq(13)-epsilon,y-sdx,seq(13)+epsilon,y-sdx, col = 2)
segments(seq(13)-epsilon, y+sdx,seq(13)+epsilon, y+sdx, col = 2)
```

Lipid composition:

```{r}
all(rownames(data) == cmps$ID)
#col_class_cmps <- colorRampPalette(brewer.pal(9, "Set1"))(length(unique(cmps$class)))
#names(col_class_cmps) <- unique(cmps$class)
col_class_cmps <- c("#E41A1C", "#974661", "#4A72A6", "#3E8E93", "#48A462", "#5D995D",
                    "#7E6E85", "#A35390", "#D16948", "#FF7F00", "#FFB716", "#FFF02D",
                    "#E1C62F", "#B97B2A", "#B75F49", "#DB728C", "#EC83BA", "#C28EA9", 
                    "#999999" )
names(col_class_cmps) <- c("FFA", "Lyso_PA", "Lyso_PE", "Lyso_PG", "Lyso_PI", "PA",
                           "PC", "PE", "PG", "PI", "PS", "CAR", "MAG", "CER", "DAG", 
                           "DGDG", "Lyso_PC", "MGDG", "TAG")
quanti <- aggregate(rowSums(data), list(cmps$class), function(x){sum(x, na.rm=T)})
slices <- quanti$x
lbls <- quanti$Group.1
pie(slices, lbls, col = col_class_cmps[lbls])
```

Proportion of discriminant compounds by class:

```{r}
tmp <- data.frame(table(cmps$class[cmps$cluster != "NS" & cmps$cluster != "high-dev"]))
tmp$Var1 <- as.character(tmp$Var1)
slices <- tmp$Freq
lbls <- tmp$Var1
pie(slices, lbls, col = col_class_cmps[lbls])
```

Proportion of discriminant compounds per compound class:

```{r}
x0 <- unique(cmps$class)[!unique(cmps$class) %in% tmp$Var1]
tmp[nrow(tmp) + 1: nrow(tmp):(length(x0)), ] <- cbind(x0, 0)
tmp <- tmp[order(tmp$Var1), ]
tmp$Total <- data.frame(table(cmps$class))[,"Freq"]
tmp$perc <- (as.numeric(tmp$Freq)/tmp$Total)*100
barplot(tmp$perc, horiz = T, 
        col = col_class_cmps[tmp$Var1], 
        names = tmp$Var1, las = 1, cex.names = 0.9)
```


Proportion of discriminant compound classes by cluster:

```{r}
par(mfrow = c(1, 2), mar = c(0, 5, 1, 4))
for(i in seq(2)){
  tmp <- cmps[cmps$cluster == paste0("c", i), ]
  tmp <- data.frame(table(tmp$class))
  tmp$Var1 <- as.character(tmp$Var1)
  slices <- tmp$Freq
  lbls <- paste0(tmp$Var1, " (n=", tmp$Freq, ")")
  pie(slices, lbls, main = paste0("c", i), 
      col = col_class_cmps[tmp$Var1])
}
```



# Session information

```{r session}
Sys.time()-startpoint
devtools::session_info()
```
